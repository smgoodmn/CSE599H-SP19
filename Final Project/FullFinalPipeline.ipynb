{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General structure taken from Jon's A4 Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # needed for plotting\n",
    "import numpy as np # numpy is primary library for numeric array (and matrix) handling\n",
    "import scipy as sp\n",
    "from scipy import stats, signal\n",
    "import random\n",
    "from sklearn import svm # needed for svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "import time\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "# for messaging\n",
    "from enum import Enum\n",
    "import serial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Capture for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## audio capture code from : https://stackoverflow.com/questions/892199/detect-record-audio-in-python\n",
    "THRESHOLD = 500\n",
    "CHUNK_SIZE = 1024*4\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 44100\n",
    "\n",
    "silent_cycles_count = 30\n",
    "min_max_begin_segment_threshold = 90 \n",
    "min_max_end_segment_threshold = 25 \n",
    "\n",
    "# RMS calc for threshold gate.\n",
    "# https://stackoverflow.com/questions/18406570/python-record-audio-on-detected-sound\n",
    "def rms(frame):\n",
    "    count = len(frame)/swidth\n",
    "    format = \"%dh\"%(count)\n",
    "    # short is 16 bit int\n",
    "    shorts = struct.unpack( format, frame )\n",
    "    sum_squares = 0.0\n",
    "    for sample in shorts:\n",
    "        n = sample * SHORT_NORMALIZE\n",
    "        sum_squares += n*n\n",
    "    # compute the rms \n",
    "    rms = math.pow(sum_squares/count,0.5);\n",
    "    return rms * 1000\n",
    "\n",
    "def is_silent(snd_data):\n",
    "    \"Returns 'True' if below the 'silent' threshold\"\n",
    "    return rms(snd_data) < THRESHOLD\n",
    "\n",
    " \n",
    "def crosses_threshold(snd_data, threshold):\n",
    "    min_max_diff = abs(np.max(snd_data) - np.min(snd_data))\n",
    "    print(\"diff: \", min_max_diff)\n",
    "    return min_max_diff >= threshold\n",
    "\n",
    "def is_cross_start_threshold(snd_data):\n",
    "    min_max_begin_segment_threshold = 90 \n",
    "    min_max_diff = abs(np.max(snd_data) - np.min(snd_data))\n",
    "    #print(\"start diff: \",min_max_diff)\n",
    "    return min_max_diff >= min_max_begin_segment_threshold\n",
    "    \n",
    "            \n",
    "    \n",
    "def is_cross_stop_threshold(snd_data):\n",
    "    min_max_continue_segment_threshold = 25 #lower threshold for continuing event\n",
    "    min_max_diff = abs(np.max(snd_data) - np.min(snd_data))\n",
    "    #print(\"end diff: \",min_max_diff)\n",
    "    return min_max_diff <= min_max_end_segment_threshold\n",
    "    \n",
    "# open port and listen\n",
    "# when over threshold, begin to store\n",
    "# when stops, segment and send\n",
    "def record(trained_model, messenger):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=1, rate=RATE,\n",
    "        input=True, output=True,\n",
    "        frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "    num_silent = 0\n",
    "    snd_started = False\n",
    "    r = array('h')\n",
    "    # current_threshold = min_max_begin_segment_threshold\n",
    "    \n",
    "    print(\"listening\")\n",
    "    \n",
    "    count = -1\n",
    "    while 1:\n",
    "        count += 1\n",
    "        \n",
    "        # little endian, signed short\n",
    "        frame = stream.read(CHUNK_SIZE)\n",
    "        snd_data = array('h', frame)\n",
    "        \n",
    "        if byteorder == 'big':\n",
    "            snd_data.byteswap()\n",
    "            \n",
    "        r.extend(snd_data)\n",
    "        \n",
    "        activity_check = rms(frame)\n",
    "        print(\"activity: {}\".format(activity_check))\n",
    "        silent = is_silent(frame)\n",
    "        \n",
    "        #silent = True\n",
    "        #snd_started = is_above_threshold(snd_data)\n",
    "        \n",
    "        if count <= 10:\n",
    "            continue\n",
    "        \n",
    "        #silent = is_silent(snd_data)\n",
    "        if silent and not snd_started:\n",
    "            continue\n",
    "            \n",
    "        #r.extend(snd_data)\n",
    "        \n",
    "        if silent and snd_started:\n",
    "            num_silent += 1\n",
    "        elif not silent and snd_started:\n",
    "            num_silent = 0\n",
    "        elif not silent and not snd_started:\n",
    "            print(\"recording\")\n",
    "            snd_started = True\n",
    "            startNum = count\n",
    "            \n",
    "        \n",
    "        # captured a sample\n",
    "        if snd_started and num_silent > silent_cycles_count:\n",
    "            \n",
    "            # captured, send to processing\n",
    "            if len(r[(startNum*CHUNK_SIZE):]) > 44100:\n",
    "                print(\"stop: silent too long\")\n",
    "                trimmed_r = r[((startNum-10)*CHUNK_SIZE):(-20*CHUNK_SIZE)]\n",
    "                sample = LiveSound(trimmed_r, RATE)\n",
    "                classification = trained_model.classifySample(sample)[0]\n",
    "                print(classification)\n",
    "                messenger.sendMessage(classification)\n",
    "                \n",
    "            else:\n",
    "                print(\"too short: \",len(r))\n",
    "                \n",
    "            count = -1\n",
    "            num_silent = 0\n",
    "            r = array('h')\n",
    "            snd_started = False\n",
    "           \n",
    "            print(\"listening\")\n",
    "\n",
    "    sample_width = p.get_sample_size(FORMAT)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    print(\"close\")\n",
    "    p.terminate()\n",
    "\n",
    "    return sample_width, r[((startNum-10)*CHUNK_SIZE):(-20*CHUNK_SIZE)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add preprocessing functions here if needed\n",
    "def preprocess(rawSignal):\n",
    "    \n",
    "    # Add preprocessing functions here if needed\n",
    "    return rawSignal\n",
    "\n",
    "class LiveSound:\n",
    "    def __init__(self, data, sampleRate):\n",
    "        self.sound = np.array(data)\n",
    "        self.sound_float = np.array(data).astype(float)\n",
    "        self.sound_p = preprocess(data)\n",
    "        self.sample_rate = sampleRate\n",
    "        \n",
    "        self.soundClassification = None\n",
    "\n",
    "\n",
    "class SoundTrial:\n",
    "    def __init__(self, soundName, trialNum, filenameWithPath):\n",
    "        self.soundName = soundName\n",
    "        self.trialNum = trialNum\n",
    "        self.filenameWithPath = filenameWithPath\n",
    "        self.filename = os.path.basename(filenameWithPath)\n",
    "        \n",
    "        sampleRate, data = wavfile.read(filenameWithPath)\n",
    "    \n",
    "        self.sound = data\n",
    "        self.sound_float = data.astype(float)\n",
    "        self.sound_p = preprocess(data)\n",
    "        self.sample_rate = sampleRate\n",
    "    \n",
    "    def __str__(self):\n",
    "         return \"'{}' : Trial {} from {}\".format(self.soundName, self.trialNum, self.filename)\n",
    "      \n",
    "    \n",
    "    \n",
    "class SoundSet:\n",
    "    def __init__(self, sound_sample_path, map_sounds_to_trials):\n",
    "        self.path = sound_sample_path\n",
    "        self.map_sounds_to_trials = map_sounds_to_trials \n",
    "        \n",
    "    # returns the base path\n",
    "    def get_base_path(self):\n",
    "        return os.path.basename(os.path.normpath(self.path))\n",
    "    \n",
    "    # returns the number of sounds\n",
    "    def get_num_sounds(self):\n",
    "        return len(self.map_sounds_to_trials)\n",
    "    \n",
    "    # returns the total number of trials\n",
    "    def get_total_num_of_trials(self):\n",
    "        numTrials = 0 \n",
    "        for soundName, trialSet in self.map_sounds_to_trials.items():\n",
    "            numTrials = numTrials + len(trialSet)\n",
    "        return numTrials\n",
    "    \n",
    "    # returns a sorted list of gesture names\n",
    "    def get_sound_names_sorted(self):\n",
    "        return sorted(self.map_sounds_to_trials.keys())\n",
    "    \n",
    "\n",
    "    # THESE HAVEN'T BEEN CHANGED YET ****************************\n",
    "    # returns the longest trial (based on num rows recorded and not clock time)\n",
    "    def get_longest_trial(self):\n",
    "        longest_trial_length = -1\n",
    "        longest_trial = None\n",
    "        for gesture_name, trial_list in self.map_gestures_to_trials.items():\n",
    "            for trial in trial_list:\n",
    "                if longest_trial_length < len(trial.accel.x):\n",
    "                    longest_trial_length = len(trial.accel.x)\n",
    "                    longest_trial = trial\n",
    "        return longest_trial\n",
    "    \n",
    "\n",
    "    \n",
    "    # returns trials for a gesture name\n",
    "    def get_trials_for_gesture(self, gesture_name):\n",
    "        return self.map_gestures_to_trials[gesture_name]\n",
    "    \n",
    "    # creates an aggregate signal based on *all* trials for this gesture\n",
    "    # TODO: in future could add in an argument, which takes a list of trial nums\n",
    "    # to use to produce aggregate signal\n",
    "    def create_aggregate_signal(self, gesture_name, signal_var_name):\n",
    "        trials = self.get_trials_for_gesture(gesture_name)\n",
    "        aggregate_signal = None\n",
    "        trial_signals = []\n",
    "        trial_signals_original = []\n",
    "        first_trial = None\n",
    "        first_trial_signal = None\n",
    "        \n",
    "        max_length = -1\n",
    "        for trial in trials:\n",
    "            trial_signal = getattr(trial.accel, signal_var_name)\n",
    "            if max_length < len(trial_signal):\n",
    "                max_length = len(trial_signal)\n",
    "            \n",
    "        for i in range(len(trials)):\n",
    "            if i == 0:\n",
    "                first_trial = trials[i]\n",
    "                trial_signal = getattr(first_trial.accel, signal_var_name)\n",
    "                trial_signal_mod = np.copy(trial_signal)\n",
    "\n",
    "                trial_signals.append(trial_signal_mod)\n",
    "                trial_signals_original.append(trial_signal)\n",
    "                \n",
    "                array_length_diff = max_length - len(trial_signal_mod)\n",
    "                trial_signal_mod = np.pad(trial_signal_mod, (0, array_length_diff), 'mean')  \n",
    "\n",
    "                aggregate_signal = trial_signal_mod\n",
    "                first_trial_signal = trial_signal_mod\n",
    "            else:\n",
    "\n",
    "                cur_trial = trials[i]\n",
    "                cur_trial_signal = getattr(trial.accel, signal_var_name) \n",
    "                trial_signals_original.append(cur_trial_signal)\n",
    "                \n",
    "                array_length_diff = max_length - len(cur_trial_signal)\n",
    "                cur_trial_signal_mod = np.pad(cur_trial_signal, (0, array_length_diff), 'mean') \n",
    "\n",
    "                cur_trial_signal_mod = get_aligned_signal_cutoff_and_pad(cur_trial_signal_mod, first_trial_signal)\n",
    "                trial_signals.append(cur_trial_signal_mod)\n",
    "                aggregate_signal += cur_trial_signal_mod\n",
    "        \n",
    "        mean_signal = aggregate_signal / len(trial_signals) \n",
    "        return mean_signal\n",
    "\n",
    "    # Returns the minimum number of trials across all gestures (just in case we accidentally recorded a \n",
    "    # different number. We should have the same number of trials across all gestures)\n",
    "    def get_min_num_of_trials(self):\n",
    "        minNumTrials = -1 \n",
    "        for gestureName, trialSet in self.map_gestures_to_trials.items():\n",
    "            if minNumTrials == -1 or minNumTrials > len(trialSet):\n",
    "                minNumTrials = len(trialSet)\n",
    "        return minNumTrials\n",
    "    \n",
    "    # get random gesture name\n",
    "    def get_random_gesture_name(self):\n",
    "        gesture_names = list(self.map_gestures_to_trials.keys())\n",
    "        rand_gesture_name = gesture_names[random.randint(0, len(gesture_names) - 1)]\n",
    "        return rand_gesture_name\n",
    "    \n",
    "    # get random trial\n",
    "    def get_random_trial(self):\n",
    "        rand_gesture_name = self.get_random_gesture_name()\n",
    "        print(\"rand_gesture_name\", rand_gesture_name)\n",
    "        trials_for_gesture = self.map_gestures_to_trials[rand_gesture_name]\n",
    "        return trials_for_gesture[random.randint(0, len(trials_for_gesture) - 1)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # prettify the str()\n",
    "    def __str__(self):\n",
    "         return \"'{}' : {} sounds and {} total trials\".format(self.path, self.get_num_sounds(), self.get_total_num_of_trials())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import ntpath\n",
    "import os\n",
    "\n",
    "# From: https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python\n",
    "def get_immediate_subdirectories(a_dir):\n",
    "    return [name for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]\n",
    "\n",
    "# Currently excludes any filenames with 'fulldatastream' in the title\n",
    "def find_wav_filenames( path_to_dir, suffix=\".wav\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix )]\n",
    "\n",
    "def parse_and_create_sound_trials( path_to_dir ):\n",
    "    wavFilenames = find_wav_filenames(path_to_dir)\n",
    "    \n",
    "    print(\"Found {} wav files in {}\".format(len(wavFilenames), path_to_dir))\n",
    "    \n",
    "    mapSoundNameToTrialList = dict()\n",
    "    mapSoundNameToMapSampleNum = dict()\n",
    "    for wavFilename in wavFilenames:\n",
    "        \n",
    "        # parse filename into meaningful parts\n",
    "        filenameNoExt = os.path.splitext(wavFilename)[0];\n",
    "        filenameParts = filenameNoExt.split(\"_\")\n",
    "            \n",
    "        soundName = filenameParts[0]\n",
    "        sampleNum = filenameParts[1]\n",
    "        fileName = \"filename\"\n",
    "        #print(\"soundName={} sampleNum={}\".format(soundName, sampleNum))\n",
    "        \n",
    "        \n",
    "        if soundName not in mapSoundNameToMapSampleNum:\n",
    "            mapSoundNameToMapSampleNum[soundName] = dict()\n",
    "            \n",
    "        if sampleNum not in mapSoundNameToMapSampleNum[soundName]:\n",
    "            mapSoundNameToMapSampleNum[soundName][sampleNum] = dict()\n",
    "            \n",
    "        mapSoundNameToMapSampleNum[soundName][sampleNum][fileName] = wavFilename\n",
    "\n",
    "        #print(mapSoundNameToMapSampleNum)\n",
    "    \n",
    "    print(\"Found {} sounds\".format(len(mapSoundNameToMapSampleNum)))\n",
    "   \n",
    "\n",
    "    # Now we need to loop through the data and sort each sound set by timems values \n",
    "    # (so that we have trial 1, 2, 3, etc. in order)\n",
    "    for soundName, mapSampleNumToFile in mapSoundNameToMapSampleNum.items():\n",
    "        soundTrialNum = 0\n",
    "        mapSoundNameToTrialList[soundName] = list()\n",
    "        for sampleNum in sorted(mapSampleNumToFile.keys()):\n",
    "            mapSampleToFile = mapSampleNumToFile[sampleNum]\n",
    "            \n",
    "            filenameWithPath = os.path.join(path_to_dir, mapSampleToFile[\"filename\"])\n",
    "            soundTrial = SoundTrial(soundName, soundTrialNum, filenameWithPath)\n",
    "            mapSoundNameToTrialList[soundName].append(soundTrial)\n",
    "            \n",
    "            soundTrialNum = soundTrialNum + 1\n",
    "        \n",
    "        print(\"Found {} trials for '{}'\".format(len(mapSoundNameToTrialList[soundName]), soundName))\n",
    "\n",
    "    return mapSoundNameToTrialList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "class MapSoundSets:\n",
    "    def __init__(self,rootSoundSamplePath=\"./SoundSamples\", targetDirWord=\"StevenTreshold\"):\n",
    "        #sets map_sound_sets\n",
    "        self.load_data(rootSoundSamplePath, targetDirWord)\n",
    "        \n",
    "    \n",
    "    def load_data(self, rootSoundSamplePath, targetDirWord):\n",
    "\n",
    "        print(get_immediate_subdirectories(rootSoundSamplePath))\n",
    "        sound_sample_paths = get_immediate_subdirectories(rootSoundSamplePath)\n",
    "\n",
    "        self.map_sound_sets = dict()\n",
    "        self.selected_sound_set = None\n",
    "\n",
    "        for sound_sample_path in sound_sample_paths:\n",
    "            path_to_sound_sample = os.path.join(rootSoundSamplePath, sound_sample_path)\n",
    "            print(\"\\nReading in:\", path_to_sound_sample)\n",
    "            map_sounds_to_trials = parse_and_create_sound_trials(path_to_sound_sample)\n",
    "            sound_set = SoundSet(sound_sample_path, map_sounds_to_trials)\n",
    "            self.map_sound_sets[sound_set.get_base_path()] = sound_set\n",
    "            if targetDirWord in sound_sample_path:\n",
    "                    self.selected_sound_set = sound_set\n",
    "\n",
    "        if self.selected_sound_set is not None:\n",
    "            print(\"\\nThe selected sound set:\", self.selected_sound_set)\n",
    "        \n",
    "\n",
    "    def get_sound_set_with_str(self, targetStr):\n",
    "        for base_path, sound_set in self.map_sound_sets.items():\n",
    "            if targetStr in base_path:\n",
    "                #print(\"set: \",sound_set)\n",
    "                return sound_set\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "# This is the simplest possible SVM using only a few features but gives you a sense of the overall approach\n",
    "# Some nice resources:\n",
    "#  - A very simple classification example using scikit: \n",
    "#     https://dbaumgartel.wordpress.com/2014/03/10/a-scikit-learn-example-in-10-lines/\n",
    "#  - A nice video overview of SVM: https://youtu.be/N1vOgolbjSc\n",
    "#  - Official sci-kit learn: http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "# Returns a feature vectof for the given trial\n",
    "def extract_features(sample):\n",
    "    \n",
    "    s = sample.sound_float\n",
    "    r = sample.sample_rate\n",
    "    \n",
    "    stft = np.abs(librosa.stft(s))\n",
    "\n",
    "    mfcc =  np.mean(librosa.feature.mfcc(y=s, sr=r, n_mfcc=50).T,axis=0)\n",
    "    \n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=r).T,axis=0)\n",
    "    \n",
    "    # This make everything seem like \"Toaster\"\n",
    "    #mel = np.mean(librosa.feature.melspectrogram(s, r).T,axis=0)\n",
    "    \n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=r).T,axis=0)\n",
    "\n",
    "    # This adds some accuracy but takes forever\n",
    "    #tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(s), sr=r).T,axis=0)\n",
    "    \n",
    "    zero_x = np.mean(librosa.feature.zero_crossing_rate(s).T,axis=0)\n",
    "    \n",
    "    features = np.hstack([mfcc, chroma, contrast, zero_x])\n",
    "    \n",
    "    \n",
    "    #print(features.shape)\n",
    "    return(features)\n",
    "\n",
    "class TrainedModel:\n",
    "\n",
    "    \n",
    "    def __init__(self, selectedSet, modelType = \"svm\", targetedString=\"Test\"):\n",
    "        self.selected_sound_set = selectedSet\n",
    "        self.numSounds = self.selected_sound_set.get_num_sounds()\n",
    "        self.numTrialsTotal = self.selected_sound_set.get_total_num_of_trials()\n",
    "\n",
    "\n",
    "        self.trainingData = np.empty((0,70))\n",
    "        self.classLabels = np.empty(0)\n",
    "\n",
    "        # build training data for this set of folds\n",
    "        #for trainingSample in self.selected_sound_set.map_sounds_to_trials:\n",
    "        #    for trainingSoundName, trainingTrial in trainingSample.items():\n",
    "        for trainingSoundName, trainingTrials in self.selected_sound_set.map_sounds_to_trials.items():\n",
    "            for trial in trainingTrials:\n",
    "                features = extract_features(trial)\n",
    "                print(\"Got features from {} #{}...\".format(trainingSoundName, trial.trialNum))\n",
    "                self.trainingData = np.vstack([self.trainingData, features])\n",
    "                self.classLabels = np.append(self.classLabels, trainingSoundName)\n",
    "\n",
    "        print(\"\\n\\n\\nFitting data...\\n\")\n",
    "\n",
    "        self._trainModel(modelType)\n",
    "\n",
    "    def _trainModel(self, modelType):\n",
    "        if modelType == \"svm\":\n",
    "            # Here, we train SVM, the 'rbf' kernal is default\n",
    "            # if you use rbf, need to set gamma and C parameters\n",
    "            # play around with different kernels, read about them, and try them. What happens?\n",
    "            # see: \n",
    "            # - https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html#sphx-glr-auto-examples-svm-plot-rbf-parameters-py\n",
    "            # - https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "            self.model = svm.SVC(kernel='linear', gamma=0.01) # kernel='rbf'\n",
    "        else:\n",
    "            self.model = svm.SVC()\n",
    "            \n",
    "        self.model.fit(self.trainingData, self.classLabels)\n",
    "        \n",
    "    def classifySample(self, liveSoundSample):\n",
    "        features = extract_features(liveSoundSample)\n",
    "        \n",
    "        prediction = self.model.predict([features])\n",
    "        return prediction\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messaging Arduino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Messenger():\n",
    "   \n",
    "    def __init__(self, port=\"/dev/cu.usbmodem1411\"):\n",
    "        \n",
    "        self.arduinoData = serial.Serial(port,9600)\n",
    "        \n",
    "        self.sounds = {\n",
    "            'GarbageDisposal':'g',\n",
    "            'MicrowaveDoorClose':'m',\n",
    "            'MicrowaveDoorOpen':'w',\n",
    "            'MicrowaveEnding':'e',\n",
    "            'Toaster' : 't',\n",
    "            'FridgeDoorOpen':'f',\n",
    "            'CoffeeGrinder':'c',\n",
    "            'FridgeDoorClose':'r'\n",
    "        }\n",
    "\n",
    "    def sendMessage(self, classification):\n",
    "        message_in_bytes = self.sounds[classification].encode('utf-8')\n",
    "        self.arduinoData.write(message_in_bytes)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6secSample', '6Test', 'Annie', 'ATest', 'Basic', 'MyKitchen', 'SMono', 'Steven', 'thresholdStop']\n",
      "\n",
      "Reading in: ./Samples\\6secSample\n",
      "Found 49 wav files in ./Samples\\6secSample\n",
      "Found 8 sounds\n",
      "Found 6 trials for 'CoffeeGrinder'\n",
      "Found 6 trials for 'FridgeDoorClose'\n",
      "Found 6 trials for 'FridgeDoorOpen'\n",
      "Found 6 trials for 'GarbageDisposal'\n",
      "Found 6 trials for 'MicrowaveDoorClose'\n",
      "Found 6 trials for 'MicrowaveDoorOpen'\n",
      "Found 6 trials for 'MicrowaveEnding'\n",
      "Found 7 trials for 'Toaster'\n",
      "\n",
      "Reading in: ./Samples\\6Test\n",
      "Found 48 wav files in ./Samples\\6Test\n",
      "Found 8 sounds\n",
      "Found 6 trials for 'CoffeeGrinder'\n",
      "Found 6 trials for 'FridgeDoorClose'\n",
      "Found 6 trials for 'FridgeDoorOpen'\n",
      "Found 6 trials for 'GarbageDisposal'\n",
      "Found 6 trials for 'MicrowaveDoorClose'\n",
      "Found 6 trials for 'MicrowaveDoorOpen'\n",
      "Found 6 trials for 'MicrowaveEnding'\n",
      "Found 6 trials for 'Toaster'\n",
      "\n",
      "Reading in: ./Samples\\Annie\n",
      "Found 37 wav files in ./Samples\\Annie\n",
      "Found 6 sounds\n",
      "Found 7 trials for 'CoffeeGrinder'\n",
      "Found 6 trials for 'FridgeDoor'\n",
      "Found 5 trials for 'GarbageDisposal'\n",
      "Found 6 trials for 'MicrowaveDoorOpen'\n",
      "Found 6 trials for 'MicrowaveEnding'\n",
      "Found 7 trials for 'Toaster'\n",
      "\n",
      "Reading in: ./Samples\\ATest\n",
      "Found 35 wav files in ./Samples\\ATest\n",
      "Found 7 sounds\n",
      "Found 5 trials for 'CoffeeGrinder'\n",
      "Found 5 trials for 'FridgeDoorClose'\n",
      "Found 5 trials for 'FridgeDoorOpen'\n",
      "Found 5 trials for 'GarbageDisposal'\n",
      "Found 5 trials for 'MicrowaveDoorClose'\n",
      "Found 5 trials for 'MicrowaveDoorOpen'\n",
      "Found 5 trials for 'MicrowaveEnding'\n",
      "\n",
      "Reading in: ./Samples\\Basic\n",
      "Found 4 wav files in ./Samples\\Basic\n",
      "Found 2 sounds\n",
      "Found 2 trials for 'CoffeeGrinder'\n",
      "Found 2 trials for 'Toaster'\n",
      "\n",
      "Reading in: ./Samples\\MyKitchen\n",
      "Found 56 wav files in ./Samples\\MyKitchen\n",
      "Found 8 sounds\n",
      "Found 7 trials for 'Faucet'\n",
      "Found 7 trials for 'FridgeDoorClose'\n",
      "Found 7 trials for 'FridgeDoorOpen'\n",
      "Found 7 trials for 'MicrowaveDoorClose'\n",
      "Found 7 trials for 'MicrowaveDoorOpen'\n",
      "Found 7 trials for 'MicrowaveEnding'\n",
      "Found 7 trials for 'OvenTimer'\n",
      "Found 7 trials for 'Silverware'\n",
      "\n",
      "Reading in: ./Samples\\SMono\n",
      "Found 45 wav files in ./Samples\\SMono\n",
      "Found 9 sounds\n",
      "Found 5 trials for 'Ambient'\n",
      "Found 5 trials for 'FridgeDoorClose'\n",
      "Found 5 trials for 'FridgeDoorOpen'\n",
      "Found 5 trials for 'MicrowaveDoorClose'\n",
      "Found 5 trials for 'MicrowaveDoorOpen'\n",
      "Found 5 trials for 'MicrowaveEnding'\n",
      "Found 5 trials for 'OvenTimer'\n",
      "Found 5 trials for 'SinkOff'\n",
      "Found 5 trials for 'SinkOn'\n",
      "\n",
      "Reading in: ./Samples\\Steven\n",
      "Found 45 wav files in ./Samples\\Steven\n",
      "Found 9 sounds\n",
      "Found 5 trials for 'Ambient'\n",
      "Found 5 trials for 'FridgeDoorClose'\n",
      "Found 5 trials for 'FridgeDoorOpen'\n",
      "Found 5 trials for 'MicrowaveDoorClose'\n",
      "Found 5 trials for 'MicrowaveDoorOpen'\n",
      "Found 5 trials for 'MicrowaveEnding'\n",
      "Found 5 trials for 'OvenTimer'\n",
      "Found 5 trials for 'SinkOff'\n",
      "Found 5 trials for 'SinkOn'\n",
      "\n",
      "Reading in: ./Samples\\thresholdStop\n",
      "Found 51 wav files in ./Samples\\thresholdStop\n",
      "Found 8 sounds\n",
      "Found 6 trials for 'CoffeeGrinder'\n",
      "Found 6 trials for 'FridgeDoorClose'\n",
      "Found 6 trials for 'FridgeDoorOpen'\n",
      "Found 6 trials for 'GarbageDisposal'\n",
      "Found 7 trials for 'MicrowaveDoorClose'\n",
      "Found 6 trials for 'MicrowaveDoorOpen'\n",
      "Found 6 trials for 'MicrowaveEnding'\n",
      "Found 8 trials for 'Toaster'\n",
      "\n",
      "The selected sound set: 'thresholdStop' : 8 sounds and 51 total trials\n",
      "Got features from CoffeeGrinder #0...\n",
      "Got features from CoffeeGrinder #1...\n",
      "Got features from CoffeeGrinder #2...\n",
      "Got features from CoffeeGrinder #3...\n",
      "Got features from CoffeeGrinder #4...\n",
      "Got features from CoffeeGrinder #5...\n",
      "Got features from FridgeDoorClose #0...\n",
      "Got features from FridgeDoorClose #1...\n",
      "Got features from FridgeDoorClose #2...\n",
      "Got features from FridgeDoorClose #3...\n",
      "Got features from FridgeDoorClose #4...\n",
      "Got features from FridgeDoorClose #5...\n",
      "Got features from FridgeDoorOpen #0...\n",
      "Got features from FridgeDoorOpen #1...\n",
      "Got features from FridgeDoorOpen #2...\n",
      "Got features from FridgeDoorOpen #3...\n",
      "Got features from FridgeDoorOpen #4...\n",
      "Got features from FridgeDoorOpen #5...\n",
      "Got features from GarbageDisposal #0...\n",
      "Got features from GarbageDisposal #1...\n",
      "Got features from GarbageDisposal #2...\n",
      "Got features from GarbageDisposal #3...\n",
      "Got features from GarbageDisposal #4...\n",
      "Got features from GarbageDisposal #5...\n",
      "Got features from MicrowaveDoorClose #0...\n",
      "Got features from MicrowaveDoorClose #1...\n",
      "Got features from MicrowaveDoorClose #2...\n",
      "Got features from MicrowaveDoorClose #3...\n",
      "Got features from MicrowaveDoorClose #4...\n",
      "Got features from MicrowaveDoorClose #5...\n",
      "Got features from MicrowaveDoorClose #6...\n",
      "Got features from MicrowaveDoorOpen #0...\n",
      "Got features from MicrowaveDoorOpen #1...\n",
      "Got features from MicrowaveDoorOpen #2...\n",
      "Got features from MicrowaveDoorOpen #3...\n",
      "Got features from MicrowaveDoorOpen #4...\n",
      "Got features from MicrowaveDoorOpen #5...\n",
      "Got features from MicrowaveEnding #0...\n",
      "Got features from MicrowaveEnding #1...\n",
      "Got features from MicrowaveEnding #2...\n",
      "Got features from MicrowaveEnding #3...\n",
      "Got features from MicrowaveEnding #4...\n",
      "Got features from MicrowaveEnding #5...\n",
      "Got features from Toaster #0...\n",
      "Got features from Toaster #1...\n",
      "Got features from Toaster #2...\n",
      "Got features from Toaster #3...\n",
      "Got features from Toaster #4...\n",
      "Got features from Toaster #5...\n",
      "Got features from Toaster #6...\n",
      "Got features from Toaster #7...\n",
      "\n",
      "\n",
      "\n",
      "Fitting data...\n",
      "\n"
     ]
    },
    {
     "ename": "SerialException",
     "evalue": "could not open port '/dev/cu.usbmodem1421': FileNotFoundError(2, 'The system cannot find the path specified.', None, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSerialException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-13eb56d4d3f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#testLive = LiveSound(test.sound, test.sample_rate)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#print(type(testLive.sound))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmessenger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMessenger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/dev/cu.usbmodem1421\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessenger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#print(trained_model.classifySample(testLive))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-c858e878a1dd>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, port)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"/dev/cu.usbmodem1411\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marduinoData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         self.sounds = {\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\serial\\serialwin32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overlapped_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overlapped_write\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSerial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\serial\\serialutil.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, port, baudrate, bytesize, parity, stopbits, timeout, xonxoff, rtscts, write_timeout, dsrdtr, inter_byte_timeout, exclusive, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;31m#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\serial\\serialwin32.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_port_handle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mwin32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINVALID_HANDLE_VALUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_port_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m    \u001b[1;31m# 'cause __del__ is called anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mSerialException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"could not open port {!r}: {!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mportstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSerialException\u001b[0m: could not open port '/dev/cu.usbmodem1421': FileNotFoundError(2, 'The system cannot find the path specified.', None, 3)"
     ]
    }
   ],
   "source": [
    "# main\n",
    "map_sound_sets = MapSoundSets()\n",
    "trained_model = TrainedModel(map_sound_sets.selected_sound_set, targetedString=\"MyKitchen\")\n",
    "\n",
    "#test = SoundTrial(\"coffee\", 0, \"./SoundSamples/6secSample/CoffeeGrinder_0_captured.wav\")\n",
    "#testLive = LiveSound(test.sound, test.sample_rate)\n",
    "#print(type(testLive.sound))\n",
    "messenger = Messenger(\"/dev/cu.usbmodem1421\")\n",
    "record(trained_model, messenger)\n",
    "#print(trained_model.classifySample(testLive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
